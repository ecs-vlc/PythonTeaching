{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "Welcome to the Data Analysis course - now that (presumably) you have a solid grasp of the principles surrounding Numerical computing in NumPy, we will move on to data management in Python. The most common way to do this is in **tabular** format (i.e in a table) with relational databases. The most commonly used powerful library which provides in-memory database-like data handling is **Pandas**. Pandas is well suited for:\n",
    "\n",
    "* **Tabular** data with heterogeneously-typed columns, such as in an SQL database or Excel spreadsheet.\n",
    "* Ordered and unordered **time-series** data.\n",
    "* Arbitrary **matrix** data with row and column labels.\n",
    "\n",
    "Some of the interesting features include:\n",
    "\n",
    "* Handling missing data fluently\n",
    "* Size mutability\n",
    "* Easy-to-use *data alignment*\n",
    "* Label-based *slicing*, *fancy indexing* and *subsetting*\n",
    "* Intuitive *merging* and *joining* of datasets by label\n",
    "* Hierarchical labelling of axes\n",
    "* Decent IO tools for importing from an array of different formats\n",
    "* Flexible reshaping and *pivoting* of tables\n",
    "\n",
    "For advanced information and API, check out the [cookbook](https://pandas.pydata.org/pandas-docs/stable/cookbook.html) and the [website documentation](https://pandas.pydata.org/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` is broken down into two primary classes:\n",
    "\n",
    "1. **Series**: think of this as an any-type (templated) unordered array with an index. A generalized *numpy array*.\n",
    "2. **DataFrame**: think of this as a 2-D heterogeneous table with a *Series* for each column.\n",
    "\n",
    "## Pandas.Series object\n",
    "\n",
    "A series is a *one-dimensional* labeled array capable of holding **any** data type (integers, strings, floating points, Python objects, etc). The axis labels are collectively referred to as the **index**. The basic method to create a *Series* is to call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.Series(data=[644, 1276, 3554, 154])\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([.25, .5, .75, 1.])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data` can be many different things:\n",
    "\n",
    "- a list\n",
    "- a Python dict\n",
    "- a `numpy.ndarray`\n",
    "- a scalar value\n",
    "\n",
    "We can also specify an **index** which needs to be the same length as `data`. If we don't specify an index, a default sequence of integers (from `np.arange()`) is assigned as the index. A numpy array comprises the values of the *Series*, which the index is another *Pandas* object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like with a NumPy array, the `series` can be accessed by the associated index via the familiar Python square-bracket notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Series` as a generalized NumPy array\n",
    "\n",
    "The essential difference between a NumPy array and `pd.Series` is the presence of an `.index` object: whilst the NumPy array has an implicitly defined integer index used, `pd.Series` has an *explicitly* defined index associated with each value that doesn't have to be numerical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.Series([644, 1276, 3554, 154], index=['Oranges', 'Apples', 'Melons', 'Pumpkins'])\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods[\"Apples\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Series` as a dictionary\n",
    "\n",
    "In this way, `pd.Series` is viewed like a specialized Python dictionary object. A dictionary is a structure that maps arbitrary keys to a set a of arbitrary values (key-value pairs). One of the key differences is that the keys and values respectively must be the same type for each value since `pd.Series` is built on top of NumPy, which in turn is built in C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_d = {\n",
    "    'Oranges': 644,\n",
    "    'Apples': 1276,\n",
    "    'Melons': 3554,\n",
    "    'Pumpkins': 154\n",
    "}\n",
    "\n",
    "food_s = pd.Series(food_d)\n",
    "food_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be achieved via separate lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Oranges', 'Apples', 'Melons', 'Pumpkins']\n",
    "counts = [644, 1276, 3554, 154]\n",
    "pd.Series(dict(zip(labels,counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike a dictionary, `pd.Series` supports array-style operations such as slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_s[\"Oranges\":\"Melons\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas.DataFrame\n",
    "\n",
    "A dataframe is a *2-dimensional* labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dictionary of Series objects. It is generally the most commonly used Pandas object. Like Series, DataFrame accepts different kinds of input:\n",
    "\n",
    "- Dict of 1D `numpy.ndarray`s, lists, dicts, or Series\n",
    "- 2-D `numpy.ndarray`\n",
    "- A Series\n",
    "- Another `DataFrame`\n",
    "\n",
    "Along with the data you can optionally pass **index** and **columns** arguments. If you pass an index and/or columns, you are guaranteeing the index and/or columns of the resulting DataFrame. Thus, a dict of Series plus a specific index will discard all data not matching up to the passed index.\n",
    "\n",
    "One of the really nice aspects about Dataframes, particularly in Jupyter notebook, is the automatic HTML/Javascript generated when visualizing tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = {'California': 38332521,'Texas': 26448193,\n",
    "              'New York': 19651127,'Florida': 19552860,\n",
    "              'Illinois': 12882135}\n",
    "area = {'California': 423967, 'Texas': 695662, 'New York': 141297,\n",
    "             'Florida': 170312, 'Illinois': 149995}\n",
    "states = pd.DataFrame({\"population\":population, \"area\":area})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the column names as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the index is accessible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual `pd.Series` can be returned using square-bracket notation to refer to the *columns* in a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[\"area\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other ways to construct a `pd.DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.random.rand(3, 2),columns=[\"foo\",\"bar\"], index=[\"a\",\"b\",\"c\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas.Index\n",
    "\n",
    "Both `Series` and `DataFrame` contain an explicit index that lets you reference and modify the rows of the data. This `Index` object is of course an interesting structure, and can be thought of as an *immutable* array or *ordered set*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = pd.Index([2, 3, 5, 7, 11])\n",
    "ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Index` operates like an array in many ways, for instance using slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also familiar are the ubiquitous shape and dimension functions common to NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ind.shape, ind.size, ind.ndim, ind.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: `Index` objects are *Immutable*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind[1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Index` object also features **set operations**, such as joins across datasets, which depend on set theory. It follows many conventions from Pythons' in-built `set` data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indA = pd.Index([1, 3, 5, 7, 9])\n",
    "indB = pd.Index([2, 3, 5, 7, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indA & indB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indA | indB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indA ^ indB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These operations have corresponding object methods, i.e `indA.intersection(indB)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Indexing and Selection\n",
    "\n",
    "For `Series`, we can use straight bracket-notation when selecting indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([.25, .5, .75, 1.], index=[\"a\",\"b\",\"c\",\"d\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"b\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use dictionary-like expressions and methods to treat the `Series` as a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"a\" in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexers: **loc**, **iloc** and **ix**\n",
    "\n",
    "Because there are many slicing and indexing conventions, where some are explicit indices, and others implicit, **Pandas** deploys a nuymber of special indexer attributes that expose certain indexing schemes.\n",
    "\n",
    "The `loc` attribute allows indexing and slicing that always references the explicit index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\"a\":\"c\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iloc` instead exposes the *implicit* positional Python-style indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ix` form of indexing is a hybrid of the two; it is recommended not to use and has been discontinued in later `pandas` versions, but we mention it for educational purposes.\n",
    "\n",
    "### Selection in DataFrame\n",
    "\n",
    "Let's use the principles we've learnt to see how to select elements in a `pd.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.loc[\"California\",\"population\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.iloc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify the object to add a column by selecting two columns and performing an operation, for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[\"density\"] = states[\"population\"] / states[\"area\"]\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This performs straightforward element-by-element arithmetic between `Series` objects.\n",
    "\n",
    "We can think of a DataFrame as a two-dimensional array, if all the values are the same type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, familar array-like observations can be done to the DataFrame, for example using transpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.iloc[:3, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.loc[:\"Illinois\",:\"population\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine familiar Numpy-style *masks* to these indexers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.loc[states.density > 100, [\"population\",\"density\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These objects returned give you direct access to the object, which allows for modification as you would in a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.iloc[0, 2] = 90\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Operations\n",
    "\n",
    "Like NumPy, Pandas allows the ability to perform fast element-wise operations, both with basic arithmetic and more sophisticated operations (trigonometric, exponential, etc). `pandas` inherits the UFuncs template from NumPy.\n",
    "\n",
    "Operations that *preserve* index and column integrity, pandas will automatically align indices when passing object to *ufunc*. This means that keeping the context of data and combining data from different sources-both potentially error-prone tasks with raw NumPy arrays-become essentially foolproof ones with `pandas`. \n",
    "\n",
    "Let's see some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.randint(0, 10, 4))\n",
    "df = pd.DataFrame(np.random.randint(0, 10, (3, 4)), columns=[\"a\",\"b\",\"c\",\"d\"])\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply a NumPy ufunc on either of these objects, the result is another Pandas object with *the indices preserved*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sin(df * np.pi / 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When UFuncs is applied on binary operations when data is incomplete, operations return `nan`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.Series({'Alaska': 1723337, 'Texas': 695662,\n",
    "                  'California': 423967}, name='area')\n",
    "population = pd.Series({'California': 38332521, 'Texas': 26448193,\n",
    "                        'New York': 19651127}, name='population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population / area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting array contains the *union* of indices of the two input arrays, which is determined by Python `set`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area.index | population.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any item which only exists in either one is marked with `NaN`, or *Not a Number*. This is Pandas' way of marking missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.Series([2, 4, 6], index=[0, 1, 2])\n",
    "B = pd.Series([1, 3, 5], index=[1, 2, 3])\n",
    "A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get around this behaviour, a fill value can be precomputed when performing certain operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.add(B, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same rules apply when using UFuncs in a DataFrame.\n",
    "\n",
    "The following table lists Python operators and their equivalent Pandas object methods:\n",
    "\n",
    "| Python Operator | Pandas Method(s) |\n",
    "| ------------ | ---------------- |\n",
    "| `+` | `add()` |\n",
    "| `-` | `sub()`, `subtract()` |\n",
    "| `*` | `mul()`, `multiply()` |\n",
    "| `/` | `truediv()`, `div()`, `divide()` |\n",
    "| `//` | `floordiv()` |\n",
    "| `%` | `mod()` |\n",
    "| `**` | `pow()` |\n",
    "\n",
    "###  Operations between DataFrame and Series\n",
    "\n",
    "When performing operations between a Frame and Series, the index and column alignment is similarly preserved and similar to NumPy array operations. One common operation would be the difference of a 2-d array and one of it's rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(10, size=(3,4))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A - A[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly in Pandas, the convention operates row-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adf = pd.DataFrame(A, columns=list(\"QRST\"))\n",
    "Adf - Adf.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to operator column-wise, use the object methods, specifyign the `axis` keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adf.sub(Adf[\"Q\"], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "One of the big differences between tutorials and the real world is that real-world data is rarely **clean** and homoegenous. Most datasets will have *some amount of data missing*. To complicate matters still, different data sources often indicate missing data in different ways. \n",
    "\n",
    "In Pandas, we represent missing values as `NaN`, `NA` or `null`, depending on data type and other factors. Pandas chooses two representations: the Pythonic `None` object, and the IEEE floating-point value `NaN` sentinel-based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.array([1, None, 3, 4])\n",
    "vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `None`: Pythonic missing data\n",
    "\n",
    "This is the Python singleton object that is used for missing data in Python code. \n",
    "\n",
    "The `dtype=object` means that the best representation NumPy can infer is that every element is a Python object. This means that operations on this object are done at the Python level and not in C, meaning very slow indeed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dtype in ['object', 'int']:\n",
    "    print(\"dtype =\", dtype)\n",
    "    %timeit np.arange(1E6, dtype=dtype).sum()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`None` also prevents common aggregation functions like `sum` or `min` across an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `NaN`: Missing numerical data\n",
    "\n",
    "This is a special floating-point value recognized by all systems that use the standard IEEE floating-point representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals2 = np.array([1, np.nan, 3, 4])\n",
    "vals2.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy has a native floating-point type for this array: meaning that this array supports fast operations pushed into compiled code. Be warned though: `NaN` can infect UFunc operations to result in `NaN`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100**5 * np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals2.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy provides special aggregations that do ignore missing values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nansum(vals2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is built to handle the two interchangeably, converting where appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1, np.nan, 2, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Files\n",
    "\n",
    "The Pandas I/O API is a set of top level reader functions accessed like `pandas.read_csv()` that generally return a Pandas object. The corresponding *writer* functions are object methods that accessed like `DataFrame.to_csv()`. Below is a table containing a sample of different readers and writers:\n",
    "\n",
    "| Format Type | Data Description | Reader  | Writer |\n",
    "| ----- | ---- | ------ | ----- | \n",
    "| text | CSV | `read_csv` | `to_csv` |\n",
    "| text | JSON | `read_json` | `to_json` |\n",
    "| text | HTML | `read_html` | `to_html` |\n",
    "| binary | MS Excel | `read_excel` | `to_excel` |\n",
    "| binary | HDF5 format | `read_hdf` | `to_hdf` |\n",
    "| SQL | SQL | `read_sql` | `to_sql` |\n",
    "\n",
    "Some important parameters to functions like `read_csv()` include:\n",
    "\n",
    "- __filepath__: The path to the file or URL\n",
    "- __sep__: The delimiter to use (for instance .csv is comma-separated, other favourites are tab-delimited \\t)\n",
    "- __header__: The row number to use a column names (and the start of the data)\n",
    "- __index_col__: The column to use as row labels of the DataFrame\n",
    "- __prefix__: Allows a prefix to be added to the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_excel(\"datasets/titanic.xlsx\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract from csv or any other flat-file k-delimited style format. This can be specified in the 'sep' argument within a call to `read_csv` or `read_table`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Aggregation\n",
    "\n",
    "The toys of NumPy are back in a similar form: max, min, mean, sum etc.\n",
    "\n",
    "Below are a list of built-in Pandas aggregations:\n",
    "\n",
    "| **Aggregation** | **Description** |\n",
    "| -------------- | ----------------- |\n",
    "| `count()` | Total number of non-NA items |\n",
    "| `first()`, `last()` | First and last item |\n",
    "| `mean()` | Arithmetic mean |\n",
    "| `median()` | Middle value |\n",
    "| `min()`, `max()` | Smallest, largest value |\n",
    "| `std()`, `var()` | Standard deviation and variance |\n",
    "| `mad()` | Mean absolute deviation |\n",
    "| `prod()` | Product of all items |\n",
    "| `sum()` | Summation of all items |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.Age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose to aggregate by more than one feature, to generate a `pandas.DataFrame` whereby the index/column names become the type of aggregation we desire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.agg(['min','max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting\n",
    "\n",
    "We can also sort the data in our Dataframes, either by sorting the values themselves, or by the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.sort_values(by='Age', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.sort_index(ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.sort_values(by=['n_parents','Fare'], ascending=[False,True]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can `rank()` each value relative to the others if desired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.Fare.rank().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts\n",
    "\n",
    "We can count the number of unique values in a column with `value_counts()` - incredibly useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Complex String columns\n",
    "\n",
    "We may wish to break down the 'name' category into title, first and last names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.Name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_names = titanic.Name.str.extract(\"(?P<Surname>[a-zA-Z]+),\\s(?P<Title>[a-zA-Z]+).\\s(?P<Forename>[a-zA-Z]+)\",\n",
    "                         expand=True)\n",
    "complex_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or alternatively, splitting a string by a common character, such as comma\n",
    "titanic.Name.str.split(\" \", expand=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "You'll be working with the **tips dataset**, which contains data regarding customers in a restaurant, how much they paid and tipped, and some characteristics about the customers such as whether they smoked or not. Most of the data is preprocessed for you already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = pd.read_csv(\"datasets/tips.csv\")\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Select all of the customers that ate at dinner time, didn't smoke, and paid more than \\$25 for their total bill **or** tipped more than \\$4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Calculate the Pearson correlation between the total bill per customer and the tip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Calculate the mean total bill and tip per customer, by day and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Sort customers by the tips and by smokers, and select the top 10 tippers who smoke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "\n",
    "**WARNING**: _Please attempt to solve the problems before fetching the solutions!_\n",
    "\n",
    "See the solutions to all of the problems here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/01_solutions.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
