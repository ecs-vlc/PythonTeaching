{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Performance\n",
    "\n",
    "Typically Python is slower than compiled languages due to **dynamic-typing**.\n",
    "\n",
    "For example, let's say you wanted to add two integers together, in C this might look like:\n",
    "\n",
    "    int a = 1;\n",
    "    int b = 2;\n",
    "    int c = a + b;\n",
    "    \n",
    "the C compiler knows from the start that a and b are integers; they cannot be anything else, hence it calls the appropriate instruction sets from assembly, returning another integer value, which might look something like:\n",
    "\n",
    "    1. Assign 1 to a\n",
    "    2. Assign 2 to b\n",
    "    3. add<int,int>(a, b)\n",
    "    4. Assign result to c\n",
    "    \n",
    "Compared to Python, which is:\n",
    "    \n",
    "    a = 1\n",
    "    b = 2\n",
    "    c = a + b\n",
    "    \n",
    "here the interpreter has no idea what type a, b and c are - only that they are *Python objects*. The interpreter must inspect the PyObject_HEAD for each variable to find the type information, then call the appropriate summation routine for the two types:\n",
    "\n",
    "    \n",
    "    Assign 1 to a\n",
    "        Set a->PyObject_HEAD->typecode to integer\n",
    "        Set a->val = 1\n",
    "    Assign 2 to b\n",
    "        Set b->PyObject_HEAD->typecode to integer\n",
    "        Set b->val = 2\n",
    "    call binary_add(a, b)\n",
    "        find typecode in a->PyObject_HEAD\n",
    "        a is an integer; value is a->val\n",
    "        find typecode in b->PyObject_HEAD\n",
    "        b is an integer; value is b->val\n",
    "        call binary_add<int, int>(a->val, b->val)\n",
    "        result of this is result, and is an integer.\n",
    "    Create a Python object c\n",
    "        set c->PyObject_HEAD->typecode to integer\n",
    "        set c->val to result\n",
    "\n",
    "### Python is Interpreted, not compiled\n",
    "\n",
    "A compiler can look ahead and optimize for repeated or unneeded operations, which can result in significant speedups, interpeters on the other hand do not have this luxury.\n",
    "\n",
    "### Python's object model leads to inefficient memory access\n",
    "\n",
    "When it comes to applying batch operations to multiple integers (in an array for instance), C is much more efficient as there is significantly *less overhead* in creating arrays, where as *Python Lists* are a contiguous buffer of *pointers* which could potential point to random areas in memory, whereas small C arrays are likely to be cached. NumPy arrays get around this by wrapping a C array with a *single Python object*.\n",
    "\n",
    "## Time\n",
    "\n",
    "Python has a *time* module that simply returns the time in seconds from the Epoch (01/01/1970)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive profiling can take place by differencing the times before and after running some code of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "t0 = time.time()\n",
    "# some function\n",
    "np.dot(np.random.randn(1000,3),np.ones((3,2))*10)\n",
    "\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the most powerful tools used in Performance analysis are part of **iPython Magicks**: %timeit, %run and %prun.\n",
    "\n",
    "Let's illustrate using the trapezoidal rule:\n",
    "\n",
    "### Trapezoidal Rule\n",
    "\n",
    "This is a method from numerical integration for approximating a definite integral:\n",
    "\n",
    "$$\n",
    "\\int_a^b f(x)dx \\approx (b-a)\\frac{f(b)-f(a)}{2}\n",
    "$$\n",
    "\n",
    "Rather than using a single interval for this estimate, we break the interval down into $n$ subintervals, to obtain a more accurate approximation:\n",
    "\n",
    "$$\n",
    "\\int_a^b f(x)dx \\approx \\sum_{k=1}^N \\frac{f(x_{k-1})+f(x_k)}{2}\\Delta x_k \n",
    "$$\n",
    "\n",
    "which for a uniform grid of equally-spaced panels becomes:\n",
    "\n",
    "$$\n",
    "I = \\frac{\\Delta x}{2}(f(x_0) + 2f(x_1) + 2f(x_2) + \\dots + 2f(x_{N-1}) + f(x_N))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 2*x*x + 3*x + 1\n",
    "\n",
    "def trapz(f, a, b, N):\n",
    "    h = (b-a)/float(N)\n",
    "    sum_y = 0\n",
    "    x = a\n",
    "    for i in range(N):\n",
    "        x += h\n",
    "        sum_y += f(x)\n",
    "    sum_y += .5 * (f(a) + f(b))\n",
    "    return sum_y*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trapz(f, 1, 5, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm this using *sympy*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sympy\n",
    "\n",
    "xs = sympy.symbols(\"xs\")\n",
    "fx = 2*xs*xs + 3*xs + 1\n",
    "ifx = sympy.integrate(fx, (xs, 1, 5))\n",
    "ifx.evalf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit trapz(f, 1, 5, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%prun trapz(f, 1, 5, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding up Python/Pandas\n",
    "\n",
    "When you have cratered under the weight of slow code, and you have profiled your code to find the bottleneck, there are a number of easy tools to speed up your code;\n",
    "\n",
    "One of these methods is making effective use of **list comprehensions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_y(x):\n",
    "    return 3*x**3 + 4*x**2 + 10*x - x**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "calcs = []\n",
    "for x in range(10000):\n",
    "    calcs.append(calculate_y(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit calcs = [calculate_y(x) for x in range(10000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A moderate speed up for very little work, and it's slightly easier to read and write\n",
    "\n",
    "## Eval\n",
    "\n",
    "In addition, Pandas provides access to *fast array expression evaluation* with eval():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x1, x2, x3 = [pd.DataFrame(np.random.normal(3.0, 2.0, size=(100000,500))) for i in range(3)]\n",
    "x1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit x1 + x2 + x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit pd.eval(\"x1 + x2 + x3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit (x1 < x2) & (x2 > x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit pd.eval(\"(x1 < x2) & (x2 > x3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfx = pd.DataFrame(np.random.randn(1000000,2), columns=['x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit dfx.x*1.5 + .25*dfx.x**2 - 3.4*dfx.y + .75*dfx.y**2 - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit dfx.eval(\"1.5*x + 0.25*x**2 - 3.4*y + 0.75*y**2 - 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculations for this can easily be *assigned* using inplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfx.eval(\"z = x<0.5\", inplace=True)\n",
    "dfx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local variables can be assigned using *const @* identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs = 0.007\n",
    "dfx.eval(\"x * @cs\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cython\n",
    "\n",
    "Python developers typically solve performance constraints by building Python extensions by wrapping code written in other compiled languages (such as C/C++). However the C/Python API is hideous complex for all but the most veteran developers.\n",
    "\n",
    "Cython is a language that allows programmers to write fast code without having to write C/C++/Fortran directly. It looks like Python code but with type declarations. Cython code is translated to C, which is then compiled to create a Python extension that we can import and use.\n",
    "\n",
    "Cython often achieves several orders of magnitude increase, often faster than hand-coded C, but can take a long time to get right.\n",
    "\n",
    "Recall our trapz() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pure Python\n",
    "\n",
    "def trapz(f, a, b, N):\n",
    "    h = (b-a)/float(N)\n",
    "    sum_y = 0\n",
    "    x = a\n",
    "    for i in range(N):\n",
    "        x += h\n",
    "        sum_y += f(x)\n",
    "    sum_y += .5 * (f(a) + f(b))\n",
    "    return sum_y*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': np.random.randn(10000),\n",
    "                   'b': np.random.randn(10000),\n",
    "                   'N': np.random.randint(100, 1000, (10000)),\n",
    "                   'x': 'x'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit df.apply(lambda x: trapz(f, x.a, x.b, x.N), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's profile to see why it's slow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%prun -l 4 df.apply(lambda x: trapz(f, x.a, x.b, x.N), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time is spent in our functions, so we should convert them to Cython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest thing we can do is simply use the **iPython Magic** to convert a Jupyter notebook block into Cython for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "def f2(x):\n",
    "    return 2*x*x + 3*x + 1\n",
    "\n",
    "def trapz2(f, a, b, N):\n",
    "    h = (b-a)/float(N)\n",
    "    sum_y = 0\n",
    "    x = a\n",
    "    for i in range(N):\n",
    "        x += h\n",
    "        sum_y += f(x)\n",
    "    sum_y += .5 * (f(a) + f(b))\n",
    "    return sum_y*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit df.apply(lambda x: trapz2(f2, x.a, x.b, x.N), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fair speed-up just by using Cython's import, now let's try and improve things by using the --annotate flag to the declaration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "def f2(x):\n",
    "    return 2*x*x + 3*x + 1\n",
    "\n",
    "def trapz2(f, a, b, N):\n",
    "    h = (b-a)/float(N)\n",
    "    sum_y = 0\n",
    "    x = a\n",
    "    for i in range(N):\n",
    "        x += h\n",
    "        sum_y += f(x)\n",
    "    sum_y += .5 * (f(a) + f(b))\n",
    "    return sum_y*h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, the colour indicates the 'typedness' of the extension, where yellower lines are closer to Python, and therefore require more calls to the Python C API, while whiter lines indicate code that is closer to pure C, hence requiring few, if any, Python API calls.\n",
    "\n",
    "Clicking on a line reveals the C code underneath the call to Cython.\n",
    "\n",
    "The goal in speeding up code with Cython is to turn as many lines to white as possible. The easiest way to do this is with type declarations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "def f3(double x):\n",
    "    return 2*x*x + 3*x + 1\n",
    "\n",
    "def trapz3(f, double a, double b, int N):\n",
    "    # declare types\n",
    "    cdef double h, x, sum_y\n",
    "    cdef int i\n",
    "    # continue\n",
    "    h = (b-a)/float(N)\n",
    "    sum_y = 0\n",
    "    x = a\n",
    "    for i in range(N):\n",
    "        x += h\n",
    "        sum_y += f(x)\n",
    "    sum_y += .5 * (f(a) + f(b))\n",
    "    return sum_y*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit df.apply(lambda x: trapz3(f3, x.a, x.b, x.N), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, another halving of the speed, just by using type declarations. The next thing we could do is inline the polynomial function. What this means is we ask the compiler to paste the function wherever it is called rather than making an expensive function call - this is particularly useful when we call $f(x)$ many, many times in the calculations of this integral, this involves:\n",
    "* changing *Python* def to cdef\n",
    "* add a return type\n",
    "* add the *inline* keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "import cython\n",
    "\n",
    "cdef inline double f4(double x):\n",
    "    return 2*x*x + 3*x + 1\n",
    "\n",
    "@cython.cdivision(True)\n",
    "cpdef double trapz4(double a, double b, int N):\n",
    "    # declare types\n",
    "    cdef double h, x, sum_y\n",
    "    cdef int i\n",
    "    # continue\n",
    "    h = (b-a)/float(N)\n",
    "    sum_y = 0\n",
    "    x = a\n",
    "    for i in range(N):\n",
    "        x += h\n",
    "        sum_y += f4(x)\n",
    "    sum_y += .5 * (f4(a) + f4(b))\n",
    "    return sum_y*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit df.apply(lambda x: trapz4(x.a, x.b, x.N), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cdef keyword declares a C object. Everything that follows it is therefore specified in terms of C; we are essentially writing C, but using a subset of Python's syntax rules. So when we create function cdef f4, it is a C function, and not available to you in Python. This is worth considering to ensure it is not called in Python by accident.\n",
    "\n",
    "cpdef keyword is however a hybrid declaration that creates both a C interface and a Python interface to the function.\n",
    "\n",
    "### Using Numpy Arrays\n",
    "\n",
    "If we profile the function now, we see that our functions are not longer near the top:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%prun -l 4 df.apply(lambda x: trapz4(x.a, x.b, x.N), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However *series* is being called a lot. This is because each row is being turned into a *series*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "cimport numpy as np\n",
    "import numpy as np\n",
    "\n",
    "import cython\n",
    "\n",
    "cdef inline double f4(double x):\n",
    "    return 2*x*x + 3*x + 1\n",
    "\n",
    "@cython.cdivision(True)\n",
    "cpdef double trapz4(double a, double b, int N):\n",
    "    # declare types\n",
    "    cdef double h, x, sum_y\n",
    "    cdef int i\n",
    "    # continue\n",
    "    h = (b-a)/float(N)\n",
    "    sum_y = 0\n",
    "    x = a\n",
    "    for i in range(N):\n",
    "        x += h\n",
    "        sum_y += f4(x)\n",
    "    sum_y += .5 * (f4(a) + f4(b))\n",
    "    return sum_y*h\n",
    "\n",
    "cpdef np.ndarray[double] apply_trapz(np.ndarray col_a, np.ndarray col_b, np.ndarray col_n):\n",
    "    assert(col_a.dtype == np.float and col_b.dtype == np.float and col_n.dtype == np.int)\n",
    "    \n",
    "    cdef Py_ssize_t i, n = len(col_n)\n",
    "    assert(len(col_a) == len(col_b) == n)\n",
    "    cdef np.ndarray[double] res = np.empty(n)\n",
    "    \n",
    "    for i in range(len(col_a)):\n",
    "        res[i] = trapz4(col_a[i], col_b[i], col_n[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit apply_trapz(df.a.values, df.b.values, df.N.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our work appears to be finished in terms of optimizations here.\n",
    "\n",
    "### Compiler Directives\n",
    "\n",
    "For example, calculating the euclidean distance between 2 arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean(x, y):\n",
    "    return np.sqrt(((x - y)**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit euclidean(np.random.randn(1000), np.random.randn(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a speed up under Cython, we need to iterate over the elements manually to aggregate them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "import cython\n",
    "cimport numpy as np\n",
    "from libc.math cimport sqrt\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def euclidean2(np.ndarray[np.float64_t, ndim=1] x, np.ndarray[np.float64_t, ndim=1] y):\n",
    "    cdef:\n",
    "        double diff\n",
    "        int i\n",
    "    diff = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        diff += (x[i] - y[i])**2\n",
    "    return sqrt(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit euclidean2(np.random.randn(1000), np.random.randn(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting *boundscheck* to False removes boundary checking for indexing operations, forcing us to ensure that we do not try to index arrays using index values that are out of bounds. When we set *wraparound* to False, Cython will not support negative indexes, as is the case with Python. Using directives is powerful, but dangerous; if we do not index properly or make some other error, it can cause segmentation faults and/or corruption.\n",
    "\n",
    "## Task\n",
    "\n",
    "Gradient descent is the method of taking steps to reduce the minimized objective function with regards to the optimum weights for a linear-regression problem. The algorithm works as:\n",
    "1. Initialise $\\bf w$ at uniform random, $i = 0$\n",
    "1. While i < maximum iterations:\n",
    "    1. Calculate $\\Delta_w \\mathbf{e}$\n",
    "    2. Update $w^{(k+1)}=w^{(k)} - \\gamma \\Delta_w \\mathbf{e}$\n",
    "1. Until convergence\n",
    "\n",
    "where $\\gamma$ is the learning rate. \n",
    "\n",
    "Run the code below in normal Python to see how fast it is with %timeit, then try to Cythonize it and see who gets the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, gamma = 1., n_iter = 10**3):\n",
    "    n, P = X.shape\n",
    "    nX = np.column_stack(((np.ones(n,)), X))\n",
    "    w = np.random.rand(P+1)\n",
    "    for i in range(1,n_iter):\n",
    "        dE = np.dot((2*nX.T),(np.dot(nX,w) - y))\n",
    "        w -= gamma*dE\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.random.normal(3.0, 1.0, size=(10000,500))\n",
    "y = np.random.randn(10000)\n",
    "%timeit gradient_descent(X, y, n_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba\n",
    "\n",
    "Where Cython pre-compiles parts of Python code before running. Another approach is **Just-in-Time (JIT)** compilation. Numba is a compiler that runs Python code through an LLVM compiler to produce optimized bytecode for fast execution. Numba doesn't need a C/C++ compiler on your machine. \n",
    "\n",
    "The *@jit* decorator runs the decorated function through bytecode analysis using a type inference engine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pairwise_py(X):\n",
    "    M, N = X.shape\n",
    "    D = np.empty((M,M), dtype=np.float64)\n",
    "    for i in range(M):\n",
    "        for j in range(M):\n",
    "            d = 0.0\n",
    "            for k in range(N):\n",
    "                tmp = X[i,k] - X[j,k]\n",
    "                d += tmp*tmp\n",
    "            D[i,j] = np.sqrt(d)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit pairwise_py(np.random.rand(1000, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def jit_pairwise_py(X):\n",
    "    M, N = X.shape\n",
    "    D = np.empty((M,M), dtype=np.float64)\n",
    "    for i in range(M):\n",
    "        for j in range(M):\n",
    "            d = 0.0\n",
    "            for k in range(N):\n",
    "                tmp = X[i,k] - X[j,k]\n",
    "                d += tmp*tmp\n",
    "            D[i,j] = np.sqrt(d)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit jit_pairwise_py(np.random.rand(1000, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see for specific functions, jit makes a huge improvement in performance. One performance caveat is that it will only speed up code that uses NumPy arrays. When your codes includes things like lists, strings or dictionaries, it will revert to *Object* mode and not provide an appreciable speedup to your code. \n",
    "\n",
    "## Task\n",
    "\n",
    "Use Numba to just-in-time compile the `gradient_descent()` function we used earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your codes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
