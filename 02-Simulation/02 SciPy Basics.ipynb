{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPy\n",
    "\n",
    "_Numpy_ provides a high-performance multidimensional array and basic tools to compute with and manipulate these arrays. **SciPy** builds on this, and provides a large number of functions that operate on numpy arrays and are useful for different types of scientific and engineering applications.\n",
    "\n",
    "The best way to get familiar with SciPy is to browse the documentation (found at [https://docs.scipy.org/doc/scipy-1.1.0/reference/tutorial/index.html]). We will highlight some parts of SciPy that you might find useful for this class.\n",
    "\n",
    "SciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data. With SciPy an interactive Python session becomes a data-processing and system-prototyping environment rivaling systems such as MATLAB, IDL, Octave, R-Lab, and SciLab.\n",
    "\n",
    "The additional benefit of basing SciPy on Python is that this also makes a powerful programming language available for use in developing sophisticated programs and specialized applications. Scientific applications using SciPy benefit from the development of additional modules in numerous niches of the software landscape by developers across the world. Everything from parallel programming to web and data-base subroutines and classes have been made available to the Python programmer. All of this power is available in addition to the mathematical libraries in SciPy.\n",
    "\n",
    "This tutorial will acquaint the first-time user of SciPy with some of its most important features. It assumes that the user has already installed the SciPy package. Some general Python facility is also assumed, such as could be acquired by working through the Python distributionâ€™s Tutorial. For further introductory help the user is directed to the Numpy documentation.\n",
    "\n",
    "For brevity and convenience, we will often assume that the main packages (numpy, scipy, and matplotlib) have been imported as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciPy Organization\n",
    "\n",
    "SciPy is organized into subpackages covering different scientific computing domains. These are summarized in the following table:\n",
    "\n",
    "| Subpackage | Description | \n",
    "| ------ | ---- |\n",
    "| `cluster` | Clustering algorithms |\n",
    "| `constants` | Physical and mathematical constants |\n",
    "| `fftpack` | Fast Fourier Transform routines |\n",
    "| `integrate` | Integration and ordinary differential equation solvers |\n",
    "| `interpolate` | Interpolation and smoothing splines |\n",
    "| `io` | Input and Output |\n",
    "| `linalg` | Linear algebra |\n",
    "| `ndimage` | N-dimensional image processing |\n",
    "| `odr` | Orthogonal distance regression |\n",
    "| `optimize` | Optimization and root-finding routines |\n",
    "| `signal` | Signal processing |\n",
    "| `sparse` | Sparse matrices and associated routines |\n",
    "| `spatial` | Spatial data structures and algorithms |\n",
    "| `special` | Special functions |\n",
    "| `stats` | Statistical distributions and functions |\n",
    "\n",
    "We will barely scratch the surface in terms of the huge expanse of libraries that **SciPy** offers, but it is recommended that each SciPy sub-package is imported separately, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg, optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration\n",
    "\n",
    "The `scipy.integrate` sub-package provides several integration techniques including an ordinary differential equation integrator. An overview of the module is provided by the `help` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Integration (quad)\n",
    "\n",
    "The function quad is provided to integrate a function of one variable between two points. The points can be ($\\pm \\infty$) to indicate infinite limits. For example, let's say you wish to integrate:\n",
    "\n",
    "$$\n",
    "I=\\int_0^{\\frac{\\pi}{2}}cos(x)dx\n",
    "$$\n",
    "\n",
    "This can be trivially computed using `integrate.quad()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = integrate.quad(lambda x: np.cos(x), 0, np.pi/2)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first value represents the *integral*, as we would expect it is extremely close to $1$. The second value represents the *absolute error* estimate within the result, as SciPy computes the integral **numerically**.\n",
    "\n",
    "If the function to integrate takes *additional parameters*, this can be provided for in the **args** argument. These parameters must be considered *constants*. Suppose that the following integral shall be calculated:\n",
    "\n",
    "$$\n",
    "I(a,b)=\\int_0^1 ax^2 + b dx\n",
    "$$\n",
    "\n",
    "This is implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrand(x, a, b):\n",
    "    return a*x**2 + b\n",
    "\n",
    "a = 2\n",
    "b = 1\n",
    "I = integrate.quad(integrand, 0, 1, args=(a,b))\n",
    "I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General multiple integration\n",
    "\n",
    "The mechanics for double and triple integration have been wrapped up into the functions `dblquad` and `tplquad`. These functions take the function to integrate and four, or six arguments, respectively. The limits of all inner integrals need to be defined as functions.\n",
    "\n",
    "An example of using double integration to compute several values of $I_n$ is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def I(n):\n",
    "    return integrate.dblquad(lambda t, x: np.exp(-x*t)/t**n, 0, np.inf, lambda x: 1, lambda x: np.inf)\n",
    "\n",
    "print(I(2))\n",
    "print(I(3))\n",
    "print(I(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration using samples\n",
    "\n",
    "If we are working with data samples across some space, we can approximate an integral of both equally-spaced and arbitrarily-spaced samples using a variety of different methods. Two of the most common are `trapz` and `simps`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,3,4])\n",
    "y = x**2\n",
    "integrate.simps(y, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corresponds exactly to:\n",
    "\n",
    "$$\n",
    "\\int_1^4 x^2 dx=21\n",
    "$$\n",
    "\n",
    "whereas integrating the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = x**3\n",
    "integrate.simps(y2, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't correspond to:\n",
    "\n",
    "$$\n",
    "\\int_1^4 x^3 dx = 63.75\n",
    "$$\n",
    "\n",
    "This is because Simpson's rule approximates the function between adjacent point as a parabola, as long as the function is a polynomial of order 2 or less with unequal spacing. Simpson's rule is more accurate than `trapz`, but `trapz` is considerably more reliable, as it interpolates *linearly* by integrating in small trapezoid parts along the sample space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary differential equations (ODEs)\n",
    "\n",
    "Integrating a set of ordinary differential equations (ODEs) given initial conditions is another useful example. The function `odeint` is available in SciPy for integrating a first-order vector differential equation:\n",
    "\n",
    "$$\n",
    "\\frac{d\\dot{y}}{dt}=f(\\dot{y},t)\n",
    "$$\n",
    "\n",
    "given initial conditions $\\dot{y}(0)=y_0$, where $\\dot{y}$ is a length $N$ vector and $f$ is a mapping from $\\mathcal{R}^N$ to $\\mathcal{R}^N$. A higher-order ordinary differential equation can always be reduced to a differential equation of this type by introducing intermediate derivatives into the $\\dot{y}$ vector.\n",
    "\n",
    "### Example\n",
    "\n",
    "The second order differential equation for the angle theta of a pendulum acted on by gravity with friction can be written:\n",
    "\n",
    "$$\n",
    "\\theta''(t) + b \\theta'(t) + c \\sin(\\theta(t)) = 0\n",
    "$$\n",
    "\n",
    "where $b$ and $c$ are care positive constants, and a prime $'$ denotes a derivative. To solve this equation with `odeint`, we first convert it to a system of first-order equations. By defining angular velocity $\\omega(t)=\\theta'(t)$, we obtain the system:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\theta'(t)=\\omega(t) \\\\\n",
    "\\omega'(t)=-b \\omega(t) - c \\sin(\\theta(t))\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Let $y$ be the vector $[\\theta, \\omega]$. We implement this system in Python as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pend(y, t, b, c):\n",
    "    theta, omega = y\n",
    "    dydt = [omega, -b*omega - c*np.sin(theta)]\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume for the initial conditions, the pendulum is nearly vertical with $\\theta(0)=\\pi - 0.1$, and is initially at rest, so $\\omega(0)=0$. Then the vector of initial conditions, with constants $b=0.25$ and $c=5.0$, is:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 0.25\n",
    "c = 5.0\n",
    "y0 = [np.pi - 0.1, 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate a solution over a uniform-space sample set in the interval $t \\in [0, 10]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0, 10, 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `odeint` to generate the solution. We pass $b$ and $c$ to `odeint` using the *args* argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = integrate.odeint(pend, y0, t, args=(b,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our solution, we have a $[101,2]$ array, whereby the first column is $\\theta(t)$ and the second is $\\omega(t)$. We plot as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(t, sol[:,0], label=r\"$\\theta(t)$\")\n",
    "plt.plot(t, sol[:,1], label=r\"$\\omega(t)$\")\n",
    "plt.xlabel(r\"$t$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation\n",
    "\n",
    "There are several general interpolation facilities available in SciPy, for data in 1, 2, and higher dimensions.\n",
    "\n",
    "The `interp1d` class in `scipy.interpolate` is a convenient method to create a function based on fixed data points which can be evaluated anywhere within the domain defined by the given data using linear interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 11, endpoint=True)\n",
    "y = np.cos(-x**2/9.)\n",
    "f = interpolate.interp1d(x, y)\n",
    "f2 = interpolate.interp1d(x, y, kind=\"nearest\")\n",
    "f3 = interpolate.interp1d(x, y, kind=\"cubic\")\n",
    "f4 = interpolate.interp1d(x, y, kind=\"next\")\n",
    "\n",
    "xnew = np.linspace(0, 10, 71, endpoint=True)\n",
    "\n",
    "fig,ax=plt.subplots(ncols=4, figsize=(15,4))\n",
    "ax[0].plot(x, y, 'o', xnew, f(xnew), 'r-', label=\"linear\")\n",
    "ax[1].plot(x, y, 'o', xnew, f2(xnew), 'g-', label=\"nearest\")\n",
    "ax[2].plot(x, y, 'o', xnew, f3(xnew), 'b-', label=\"cubic\")\n",
    "ax[3].plot(x, y, 'o', xnew, f4(xnew), 'k-', label=\"next\")\n",
    "for a in ax:\n",
    "    a.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate data interpolation\n",
    "\n",
    "Suppose you have multidimensional data, for instance for an underlying function $f(x, y)$ you only know the values at points ($x[i]$, $y[i]$) that do not form a regular grid.\n",
    "\n",
    "Suppose we want to interpolate the 2-D function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x, y):\n",
    "    return x*(1-x)*np.cos(4*np.pi*x) * np.sin(4*np.pi*y**2)**2\n",
    "\n",
    "grid_x, grid_y = np.mgrid[0:1:100j, 0:1:200j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but we only know its values at 1000 data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.random.rand(1000, 2)\n",
    "values = func(points[:,0], points[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done with `griddata` â€“ below we try out all of the interpolation methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_z0 = interpolate.griddata(points, values, (grid_x, grid_y), method=\"nearest\")\n",
    "grid_z1 = interpolate.griddata(points, values, (grid_x, grid_y), method=\"linear\")\n",
    "grid_z2 = interpolate.griddata(points, values, (grid_x, grid_y), method=\"cubic\")\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(15,4))\n",
    "\n",
    "for i,p in enumerate([grid_z0, grid_z1, grid_z2]):\n",
    "    ax[i].imshow(p)\n",
    "for i,c in enumerate([\"nearest\",\"linear\",\"cubic\"]):\n",
    "    ax[i].set_title(c)\n",
    "    ax[i].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spline interpolation\n",
    "\n",
    "Spline interpolation requires two essential steps: (1) a spline representation of the curve is computed, and (2) the spline is evaluated at the desired points. In order to find the spline representation, there are two different ways to represent a curve and obtain (smoothing) spline coefficients: directly and parametrically. The direct method finds the spline representation of a curve in a two- dimensional plane using the function `splrep`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 2*np.pi+np.pi/4, 2*np.pi/8)\n",
    "y = np.sin(x)\n",
    "tck = interpolate.splrep(x, y, s = 0)\n",
    "tck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keyword argument, s , is used to specify the amount of smoothing to perform during the spline fit. The default value of $s$ is $s=m-\\sqrt{2m}$ where $m$ is the number of data points being fit. Thus if no smoothing is desired $s=0$.\n",
    "\n",
    "Once the spline representation of the data has been determined, functions are available for evaluating the spline (`splev`) and its derivatives (`splev`, `spalde`) at any point and the integral of the spline between any two points ( `splint`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnew = np.arange(0, 2*np.pi, np.pi/50)\n",
    "ynew = interpolate.splev(xnew, tck, der=0)\n",
    "\n",
    "plt.plot(x, y, 'x', xnew, ynew, xnew, np.sin(xnew), x, y, 'b')\n",
    "plt.legend([\"Linear\",\"Cubic\",\"True\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional image processing\n",
    "\n",
    "Image processing and analysis are generally seen as operations on two-dimensional arrays of values. There are however a number of fields where images of higher dimensionality must be analyzed. Good examples of these are **medical imaging** and **biological imaging**. `numpy` is suited very well for this type of applications due its inherent multidimensional nature. The `scipy.ndimage` packages provides a number of general image processing and analysis functions that are designed to operate with arrays of arbitrary dimensionality. The packages currently includes functions for linear and non-linear filtering, binary morphology, B-spline interpolation, and object measurements.\n",
    "\n",
    "To access this functionality, we import the `ndimage` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing images from file\n",
    "\n",
    "Creating a numpy array from an image file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(ncols=3, figsize=(15,5))\n",
    "\n",
    "fly = plt.imread(\"butterfly.jpg\")\n",
    "print(fly.shape, fly.dtype)\n",
    "ax[0].imshow(fly)\n",
    "for a in ax:\n",
    "    a.axis(\"off\")\n",
    "# different interpolations\n",
    "ax[1].imshow(fly, interpolation=\"bilinear\")\n",
    "ax[2].imshow(fly, interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Manipulations\n",
    "\n",
    "Including **masking** and **rotation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy to manipulate\n",
    "porthole_fly = fly.copy()\n",
    "\n",
    "lx, ly, lz = fly.shape\n",
    "X, Y = np.ogrid[0:lx, 0:ly]\n",
    "mask = (X - lx / 2) **2 + (Y - ly / 2) **2 > lx * ly / 4\n",
    "\n",
    "porthole_fly[mask,:] = 0\n",
    "\n",
    "fig,ax=plt.subplots(ncols=2, figsize=(14,5))\n",
    "\n",
    "ax[0].imshow(porthole_fly)\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "fly_rot = ndimage.rotate(fly, 45, reshape=False)\n",
    "ax[1].imshow(fly_rot)\n",
    "ax[1].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blurring/Smoothing\n",
    "\n",
    "Note that this has selected only on the *gray* channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = ndimage.gaussian_filter(fly, sigma=3)\n",
    "very_blurred = ndimage.gaussian_filter(fly, sigma=5)\n",
    "unif_fly = ndimage.uniform_filter(fly, size=11)\n",
    "\n",
    "fig,ax=plt.subplots(ncols=3, figsize=(15,7))\n",
    "for a in ax:\n",
    "    a.axis(\"off\")\n",
    "ax[0].imshow(blurred)\n",
    "ax[1].imshow(very_blurred)\n",
    "ax[2].imshow(unif_fly)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpening\n",
    "\n",
    "To sharpen an image, we apply a blurring filter and then remove the gaussian filter from the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_blurred = ndimage.gaussian_filter(blurred, 1)\n",
    "# select an alpha\n",
    "alpha = 5\n",
    "sharpened = blurred + alpha * (blurred - filter_blurred)\n",
    "\n",
    "fig,ax=plt.subplots(ncols=2, figsize=(15,7))\n",
    "ax[0].imshow(fly)\n",
    "ax[1].imshow(sharpened)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection\n",
    "\n",
    "We can use a **gradient operator** (Sobel) to find high intensity variations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = np.zeros((256,256))\n",
    "sq[64:-64, 64:-64] = 1\n",
    "sq = ndimage.rotate(sq, 30, mode=\"constant\")\n",
    "sq = ndimage.gaussian_filter(sq, 8)\n",
    "\n",
    "sx = ndimage.sobel(sq, axis=0, mode=\"constant\")\n",
    "sy = ndimage.sobel(sq, axis=1, mode=\"constant\")\n",
    "sob = np.hypot(sx, sy)\n",
    "\n",
    "fig, ax=plt.subplots(ncols=3, figsize=(15,4))\n",
    "for a in ax:\n",
    "    a.axis(\"off\")\n",
    "for i,p in enumerate([sx, sy, sob]):\n",
    "    ax[i].imshow(p, cmap=\"hot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is substantially more that can be found with processing images, however the scope of this session is just to cover some basic operations to show how things can be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Matrices\n",
    "\n",
    "Normal matrices are 2-D objects that store numerical values, and every value is stored in memory in a contiguous chunk. This provides benefits such as very fast access to individual items, but what about when most of the data values are null?\n",
    "\n",
    "We can use `scipy.sparse` for a selection of different strategies for representing **sparse** data, and it even helps when we have cases where memory grows exponentially.\n",
    "\n",
    "Sparse matrices act to *compress* the data to save memory usage, by not representing zero values. Applications include:\n",
    "\n",
    "- solution to partial differential equations (finite elements etc.)\n",
    "- graph theory (nodes and edges)\n",
    "\n",
    "Sparsity can be visualised with `matplotlib` using `plt.spy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sp = np.random.choice([0, 1], size=(200,200), p=[.95, .05])\n",
    "plt.spy(X_sp, cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse matrices offer the data structure to store large, sparse matrices, and allows us to perform complex matrix computations. The ability to do such computations is incredibly powerful in a variety of data science problems. Learning to work with Sparse matrix, a large matrix or 2d-array with a lot elements being zero, can be extremely handy.\n",
    "\n",
    "Pythonâ€™s SciPy library has a lot of options for creating, storing, and operating with Sparse matrices. There are 7 different types of sparse matrices available.\n",
    "\n",
    "1. __csc_matrix__: Compressed Sparse Column format\n",
    "1. __csr_matrix__: Compressed Sparse Row format\n",
    "1. __bsr_matrix__: Block Sparse Row format\n",
    "1. __lil_matrix__: List of Lists format\n",
    "1. __dok_matrix__: Dictionary of Keys format\n",
    "1. __coo_matrix__: COOrdinate format\n",
    "1. __dia_matrix__: DIAgonal format\n",
    "\n",
    "The default type is the **csr_matrix**, and NumPy converts your sparse matrix to this format before it conducts arithmetic operations on it. The table below highlights the opportunities of each format:\n",
    "\n",
    "\n",
    "| format | matrix `*` vector | get item | fancy get | set item | fancy set | solvers | note | \n",
    "| ------ | ---- | ------ | ---- | ------ | ---- | ------ | ---- |\n",
    "| DIA | sparsetools | . | . | . | . | iterative | has data array, specialized |\n",
    "| LIL | via CSR | yes | yes | yes | yes | iterative | arithmetics via CSR, incremental construction |\n",
    "| DOK | python | yes | one axis only | yes | yes | iterative | O(1) item access, incremental construction |\n",
    "| COO | sparsetools | . | . | . | . | iterative | has data array, facilitates fast conversion |\n",
    "| CSR | sparsetools | yes | yes | slow | . | any | has data array, fast row-wise operations |\n",
    "| CSC | sparsetools | yes | yes | slow | . | any | has data array, fast column-wise operations |\n",
    "| BSR | sparsetools | . | . | . | . | specialized | has data array, specialized |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING**: When multiplying `scipy.sparse` matrices, it acts as *matrix multiplication* (i.e dot product), not element-wise.\n",
    "\n",
    "### Example\n",
    "\n",
    "Here we will create a **lil_matrix**, assign some random numbers, convert to CSR and use `sparse.solve`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size = 10000\n",
    "subsets = 1000\n",
    "A = sparse.lil_matrix((dim_size,dim_size))\n",
    "A[0, :subsets] = np.random.rand(subsets)\n",
    "A[1, subsets:subsets*2] = np.random.rand(subsets)\n",
    "A.setdiag(np.random.rand(dim_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A.tocsr()\n",
    "b = np.random.rand(dim_size)\n",
    "# solve using scipy.sparse.linalg\n",
    "x = sparse.linalg.spsolve(A, b)\n",
    "# solve non-sparse by converting A back to numpy!\n",
    "x_ = np.linalg.solve(A.toarray(), b)\n",
    "# error between methods\n",
    "err = np.linalg.norm(x - x_)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSC/CSR format\n",
    "\n",
    "These are the best formats, as they allow for fast matrix-vector products and other arithmetics along the appropriate axis, in addition to efficient row/column slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.choice([0,1], size=(5,5), p=[.8, .2])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.csc_matrix(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sparse.csr_matrix(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagonal sparse matrices\n",
    "\n",
    "This is natural, as a diagonal matrix is by definition mostly sparse, only containing non-zero values on the *diagonal* of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sparse.dia_matrix(np.ones((10000,10000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "\n",
    "## Task 1\n",
    "\n",
    "The force $F$ on an area $A$ at a depth $y$ in a liquid of density $w$ is given by:\n",
    "\n",
    "$$\n",
    "F=wyA\n",
    "$$\n",
    "\n",
    "Imagine this applied to a plate submerged vertically in a liquid.\n",
    "\n",
    "The **total force** on the plate is given by:\n",
    "\n",
    "$$\n",
    "F=w\\int_a^b xy \\, dy\n",
    "$$\n",
    "\n",
    "where $x$ is the length (in m) of the element of area expressed in terms of $y$, $y$ is depth (in m) of the element of area, $w$ is the density of the liquid (in $Nm^{-3}$), $a$ is the depth at the top of the area (in m), and $b$ is the depth at the bottom of the area (in m).\n",
    "\n",
    "Calculate the force on one side of a cubical container 10.0cm on an edge if the container is filled with water. The weight density of water is $w=9800Nm^{-3}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Consider the motion of a spring that is subject to a frictional force or a damping force. An example is the damping force supplied by a shock absorber in a car or a bicycle. We assume that the damping force is proportion to the velocity of the mass and acts in the direction opposite to the motion. Thus:\n",
    "\n",
    "$$\n",
    "F_d=-c\\frac{dx}{dt}\n",
    "$$\n",
    "\n",
    "where $c$ is a damping constant. Newton's second law thus gives:\n",
    "\n",
    "$$\n",
    "m\\frac{d^2x}{dt^2}=F_r + F_d=-kx-c\\frac{dx}{dt}\n",
    "$$\n",
    "\n",
    "which we re-arrange to:\n",
    "\n",
    "$$\n",
    "m\\frac{d^2x}{dt^2}+c\\frac{dx}{dt}+kx=0\n",
    "$$\n",
    "\n",
    "Solve the linear system of equations using `odeint`, with initial conditions $x(0)=0$ and $x'(0)=0.6$. Ensure that $m$, $c$ and $k$ are all positive constants, but initially test with $m=5$, $c=10$ and $k=128$. Create a timespace as $t \\in [0, 10]$ with a sensible number of steps.\n",
    "\n",
    "Once you done one run, try tweaking $m$ and $c$ and see the different plots you find.\n",
    "\n",
    "Ensure that you plot both $x(t)$ and $x'(t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Import the image `bigcat.jpg`. Compute the laplace transformation from the method `laplace()` found in `ndimage`. Plot the image of the big cat and it's laplace transformation. How well does the image capture the big cat from the scenery?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Trying different $\\sigma$, draw 9 laplace-transformed cats using 9 different values for in the logspace range of $\\sigma \\in [10^{-1}, 5]$, within a `gaussian_filter()`. Print the sigma at the top of each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "We can try to label groups of pixels in this image using `ndimage.label`, which accepts a boolean matrix. This boolean matrix which it tries to associate groups to can be generated by a number of ways; in this instance we will simply select points that are greater than the pixel mean across all pixels:\n",
    "\n",
    "$$\n",
    "B_{ij}=\n",
    "\\begin{cases}\n",
    "1 & B_{ij} > \\bar{B} \\\\\n",
    "0 & B_{ij} \\le \\bar{B} \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Plot 3 images:\n",
    "1. The labelled unfiltered image\n",
    "2. The labelled laplacian-gaussian filtered image\n",
    "3. The labelled sobel-filtered image\n",
    "\n",
    "Sobel-filters can be generated using `ndimage.sobel`. You may choose to use a gaussian filter and/or laplace transform before using `sobel()`.\n",
    "\n",
    "You may use any parameters to `gaussian_filter(sigma)` as necessary to get interesting results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your codes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
