{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations 1\n",
    "\n",
    "This notebook will involve no direct teaching - instead we are going to attempt to solve a number of difficult problems. These problems will attempt to range over a number of inter-disciplinary fields. Don't worry if you are not able to complete them all within the time of the workshop - they are meant to stretch your abilities, gain some useful NumPy experience and grow some inter-disciplinary knowledge. For these tasks we require that you **only** use NumPy arrays as this is considerably faster and the only tractable method in later examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "\n",
    "## Monte Carlo Integration\n",
    "\n",
    "*Monte Carlo methods* rely primarily on repeated sampling to obtain numerical results, and are used extensively in any application that involves a probabilistic interpretation. They are particularly powerful in *high-dimensional* problems where deterministic methods for high dimensions become intractable. They are often coupled with other techniques such as **Markov Chains** once the probability distribution of a variable is parameterized.\n",
    "\n",
    "Let's say we have a mathematical function that is difficult to integrate:\n",
    "\n",
    "$$\n",
    "f(x)=\\sin^2 \\left(\\frac{1}{x(2-x)}\\right)\n",
    "$$\n",
    "\n",
    "to see this, do a quick plot.\n",
    "\n",
    "We see that the infinite oscillation as $f(x)$ draws towards 0 and 2 makes this function incredibly difficult to integrate using standard numerical methods (composite trapezoidal, simpsons).\n",
    "\n",
    "However we can make use of the fact that this function is *bounded* at [0, 2], and **scatter** a large uniform random distribution $\\cal N[0, 1]$ across this box. The fraction of them falling below the curve is approximately the integral we want to compute; hence:\n",
    "\n",
    "$$\n",
    "I=\\int_a^b f(x) \\ dx \\quad \\implies \\quad I \\simeq \\frac{k A}{N}\n",
    "$$\n",
    "\n",
    "where $N$ is the total number of points considered, $k$ is the number falling below the curve, and $A$ is the area of the box. We know that $x \\in [0, 2]$, and we choose $y \\in [0, 1]$, giving $A=(y_1-y_0)(x_1-x_0)$.\n",
    "\n",
    "### Task 1\n",
    "\n",
    "Write a function `monte_carlo_integrate()` which receives the function $f(x)$, the domain of $x$, the domain of $y$, and $N$. It should compute the integral of `f(x)` using the Monte Carlo method. Remember that the random numbers generated *must* be scaled into the domains of $x$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write codes here\n",
    "def monte_carlo_integrate(f, dx, dy, N):\n",
    "\tarea = (dx[1] - dx[0])*(dy[1] - dy[0])\n",
    "\t# generate random numbers in 2-d\n",
    "\tpairs = np.random.rand(N,2)\n",
    "\t# move pairs into domain [x,y]\n",
    "\tpairs[:,0] *= dx[1] - dx[0]\n",
    "\tpairs[:,0] += dx[0]\n",
    "\tpairs[:,1] *= dy[1] - dy[0]\n",
    "\tpairs[:,1] += dy[0]\n",
    "\t# x is in [:,0]\n",
    "\tintegrand = f(pairs[:,0])\n",
    "\t# choose k where random numbers y fall below the integrand\n",
    "\tk = pairs[:,1] < integrand\n",
    "\t\n",
    "\treturn (area * np.sum(k)) / N "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Call `monte_carlo_integrate()` with the function described above, with $x \\in [0, 2]$, $y \\in [0, 1]$, and $N=10^5$. Is it reasonable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write codes here\n",
    "def f(x):\n",
    "\treturn np.sin(1/(x*(2-x)))**2\n",
    "\n",
    "I = monte_carlo_integrate(f, [0, 2], [0, 1], 10**5)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 3\n",
    "\n",
    "The area of a circle of radius 2 is $4\\pi$. To help check the accuracy, let's calculate $\\pi$ by calculating the area of a *quarter-circle* in $x,y \\in [0, 2]$:\n",
    "\n",
    "$$\n",
    "\\pi = \\int_0^2 \\sqrt{4-x^2} \\ dx\n",
    "$$\n",
    "\n",
    "Repeat calls to `monte_carlo_integrate()` and generate integrals of Monte-Carlo integration with $N$. We recommend using $N=100 \\times 2^i$ for $i=0,\\dots,15$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write codes here\n",
    "def pi(x):\n",
    "\treturn np.sqrt(4-x**2)\n",
    "\n",
    "Nvals = 100*2**np.arange(0,15)\n",
    "errs = np.zeros((15,))\n",
    "\n",
    "for i, N in enumerate(Nvals):\n",
    "\terrs[i] = abs(monte_carlo_integrate(pi, [0, 2], [0, 2], N ) - np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Generate the loglog plot of $N$ against $E$, also known as the **convergence** of the algorithm, where:\n",
    "\n",
    "$$\n",
    "E= \\lvert \\pi-\\hat \\pi \\rvert\n",
    "$$\n",
    "\n",
    "where $\\hat \\pi = I$ integral from our Monte-Carlo method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write codes here\n",
    "plt.loglog(Nvals, errs, 'kx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "The coefficients for the slope (m) and intercept (b) can be calculated with `np.polyfit(N,E,1)`, remember to pass the $\\log N$ and $\\log E$! Plot the slope line through the points using loglog, using $y=mx+b$ for the $y$ variables. However given that the plot is in logspace, we calculate $y$ as:\n",
    "\n",
    "$$\n",
    "y=\\exp(b)N^m\n",
    "$$\n",
    "\n",
    "Calculate and plot the slope of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write codes here\n",
    "plt.loglog(Nvals, errs, 'kx')\n",
    "m,b = np.polyfit(np.log(Nvals), np.log(errs), 1)\n",
    "plt.loglog(Nvals, np.exp(b)*Nvals**m, 'b--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ising Model\n",
    "\n",
    "The Ising Model is a simplified two-dimensional representation of a magnet. A regular, square, $N \\times N$ lattice represents the sites which have individual magnetic *spins*, which are $\\pm 1$: so $S_{ij}$ is the spin at site $(i,j)$. The total energy of the magnet is given by the sum of the nearest-neighbour interaction energies:\n",
    "\n",
    "$$\n",
    "E=-J \\sum_{i,j=0}^{N-1}\\left(S_{i-1,j}+S_{i+1,j}+S_{i,j-1}+S_{i,j+1} \\right)\n",
    "$$\n",
    "\n",
    "where $J$ is the strength of the interaction which we will set to $1$ throughout. Period boundaries are used for the magnet:\n",
    "\n",
    "$$\n",
    "S_{-1,j}=S_{N-1,j}, \\\\\n",
    "S_{N,j}=S_{0,j}, \\\\\n",
    "S_{i,-1}=S_{i,N-1}, \\\\\n",
    "S_{i,N}=S_{i,0}\n",
    "$$\n",
    "\n",
    "If the spin of one site $(i,j)$ is flipped then the energy change is:\n",
    "\n",
    "$$\n",
    "\\Delta_E=2J S_{ij} \\left(S_{i-1,j}+S_{i+1,j}+S_{i,j-1}+S_{i,j+1} \\right)\n",
    "$$\n",
    "\n",
    "The total (average) magnetization is:\n",
    "\n",
    "$$\n",
    "M=\\frac{1}{N^2} \\sum_{i,j=0}^{N-1} S_{ij}\n",
    "$$\n",
    "\n",
    "This model can be effective solved using the **Metropolis-Hastings** algorithm. \n",
    "\n",
    "The Metropolis-Hastings algorithm starts from the assumption that the ground state will try to minimize its energy. Therefore the samples $n_j$ with energy $E_j$ is \"better\" than the samples $n_i$ with energy $E_i$ if $E_j<E_i$.\n",
    "\n",
    "However, the rule to only accept a transition from samples with high energy to samples with low energy doesn't match detailed balance. There must be some chance of moving to a state with higher energy. This probability must match the qualitative form of the overall distribution. If we make the assumption that the energies follow the Boltzmann distribution, then the chance of a state appearing with $E_j>E_i$ is $∼\\exp[−\\beta(E_j−E_i)]$, where $\\beta$ is $k_BT$ ($k_B$ is the Boltzmann constant and $T$ the temperature of the system)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Write a function, `calc_positional_e()`, which accepts a 2-D matrix of magnetic spins with $J$, and factoring in periodic boundaries, **only** calculates the sum of the nearest-neighbour interactions.\n",
    "\n",
    "**NOTE**: There are a few strategies to do this; but a naive approach which uses native Python `for` loops will not be effective when we scale up. You will need to deploy some performance-boosting method such as `Cython` or `jit` if you take that route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def calc_positional_e(spins, J):\n",
    "    \"\"\"\n",
    "    In this strategy, we use pure Python and beef up our code with JIT or Cython.\n",
    "    \"\"\"\n",
    "    N = spins.shape[0]\n",
    "    E = np.zeros_like(spins)\n",
    "    # for loop\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i == 0:\n",
    "                spin_l = spins[N-1,j]\n",
    "                spin_r = spins[i+1,j]\n",
    "            elif i == N-1:\n",
    "                spin_l = spins[i-1,j]\n",
    "                spin_r = spins[0,j]\n",
    "            else:\n",
    "                spin_l = spins[i,j-1]\n",
    "                spin_r = spins[i,j+1]\n",
    "                \n",
    "            if j == 0:\n",
    "                spin_u = spins[i,N-1]\n",
    "                spin_d = spins[i,j+1]\n",
    "            elif j == N-1:\n",
    "                spin_u = spins[i,j-1]\n",
    "                spin_d = spins[i,0]\n",
    "            else:\n",
    "                spin_u = spins[i,j-1]\n",
    "                spin_d = spins[i,j+1]\n",
    "                \n",
    "            E[i,j] = spin_l + spin_r + spin_u + spin_d\n",
    "    return E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Write a function, `delta_e()`, which calculates the change in energy at site $(i,j$), accepting a 2-D matrix as a parameter (subset of the whole magnet), with $i$, $j$, and $J$. Test your method with a couple of random magnets and random indices, you should expect values in the range $-4 \\lt x \\lt 4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def delta_e(spins, i, j, J):\n",
    "    N = spins.shape[0]\n",
    "    # check boundaries first!\n",
    "    if i == 0:\n",
    "        spin_l = spins[N-1,j]\n",
    "        spin_r = spins[i+1,j]\n",
    "    elif i == N-1:\n",
    "        spin_l = spins[i-1,j]\n",
    "        spin_r = spins[0,j]\n",
    "    else:\n",
    "        spin_l = spins[i-1,j]\n",
    "        spin_r = spins[i+1,j]\n",
    "\n",
    "    if j == 0:\n",
    "        spin_u = spins[i,N-1]\n",
    "        spin_d = spins[i,j+1]\n",
    "    elif j == N-1:\n",
    "        spin_u = spins[i,j-1]\n",
    "        spin_d = spins[i,0]\n",
    "    else:\n",
    "        spin_u = spins[i,j-1]\n",
    "        spin_d = spins[i,j+1]\n",
    "        \n",
    "    return 2. * J * spins[i,j] * (spin_l+spin_r+spin_u+spin_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Write a function, `total_mag_e()`, which calculates the total magnetic energy of a 2-D matrix, given their magnetic spins and $J$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_mag_e(spins, J):\n",
    "    return -J*np.sum(calc_positional_e(spins, J))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Write the `metropolis_hastings()` algorithm, as described above, with parameters $N$, `n_steps` and $\\beta$ using the following pseudocode as guidance:\n",
    "\n",
    "    Set variable spins: numpy array of size N x N, with random -1/+1.\n",
    "    Set variable J: 1\n",
    "    Set variable E_series: empty numpy array of size `steps`\n",
    "    Set the first step of E_series: as the total magnetic energy.\n",
    "    For loop: increment step;\n",
    "        Set random variable randx: U[0,N]\n",
    "        Set random variable randy: U[0,N]\n",
    "        Set variable delta_E: call function\n",
    "        if delta_E < 0 or random variable U[0,1] < boltzmann distribution:\n",
    "            Flip the spin at site [randx,randy]\n",
    "            E_series[step] = E_series[step-1] + delta_E\n",
    "        else:\n",
    "            E_series[step] = E_series[step-1]\n",
    "    Returns spins, E_series\n",
    "    \n",
    "where `randx` and `randy` are random variables drawn from an integer distribution between $0$ and $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings(N, n_steps, beta):\n",
    "    spins = np.random.choice([-1,1], size=(N,N))\n",
    "    J = 1\n",
    "    E_series = np.ones(n_steps)\n",
    "    E_series[0] = total_mag_e(spins, J)\n",
    "    \n",
    "    for s in range(1, n_steps):\n",
    "        randx = np.random.randint(N)\n",
    "        randy = np.random.randint(N)\n",
    "        # calculate de\n",
    "        dE = delta_e(spins, randx, randy, J)\n",
    "        # if we decrease the energy or meet boltzmann requirements, flip the spin\n",
    "        if dE < 0. or np.exp(-beta*dE) > np.random.rand():\n",
    "            spins[randx, randy] *= -1\n",
    "            E_series[s] = E_series[s-1] + dE\n",
    "        else:\n",
    "            E_series[s] = E_series[s-1]\n",
    "    return spins, E_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "Run the `metropolis_hastings()` algorithm with $N=40$, $\\beta=0.1$ and $\\beta=1$. Try using $2\\times10^5$ iterations. Plot the resulting energy series returned from the function against the number of iterations.\n",
    "\n",
    "In addition, plot the final state of each magnet, using each $\\beta$ value, using `plt.imshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = metropolis_hastings(40, int(5*10**5), 0.1)\n",
    "B = metropolis_hastings(40, int(5*10**5), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(ncols=3, figsize=(16,4))\n",
    "\n",
    "ax[0].plot(A[1], label=r\"$\\beta=0.1$\")\n",
    "ax[0].plot(B[1], label=r\"$\\beta=1.0$\")\n",
    "ax[0].legend()\n",
    "ax[1].imshow(A[0], cmap=\"gray\")\n",
    "ax[2].imshow(B[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "\n",
    "Using a lattice of $20^2$ sites, and $5 \\times 10^5$ steps, over $50$ different $\\beta \\in [0.1, 0.6]$, plot $\\beta$ against the *average magnetization* (see function above!). What do you see happening to the magnet as $\\beta$ increases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bvals = 50\n",
    "betas = np.linspace(0.1, 0.6, bvals)\n",
    "m_ser = np.zeros(bvals)\n",
    "\n",
    "def average_magnetization(spins, N):\n",
    "    return (1 / N**2) * np.sum(spins)\n",
    "\n",
    "for b in range(bvals):\n",
    "    # print(\"Running beta=%.4f\" % betas[b])\n",
    "    C, E = metropolis_hastings(20, 500000, betas[b])\n",
    "    m_ser[b] = average_magnetization(C[0], 20)\n",
    "    \n",
    "# plot\n",
    "fig = plt.figure(figsize=(13,5))\n",
    "plt.plot(betas, m_ser, \"g*\")\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "plt.ylabel(r\"$M$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 (Optional)\n",
    "\n",
    "Try to find performance gains on your `metropolis_hastings()` algorithm by modifying the code, and using `%prun` to profile your function and see where the majority of time is spent.\n",
    "\n",
    "Try to get gains by using **Cython** also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun metropolis_hastings(40, 500000, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit metropolis_hastings(40, 500000, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "from libc.math cimport exp\n",
    "\n",
    "cdef extern from \"stdlib.h\":\n",
    "    double drand48()\n",
    "    void srand48(long int seedval)\n",
    "    \n",
    "cdef extern from \"time.h\":\n",
    "    long int time(int)\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "cdef double calc_positional_e(np.ndarray[np.int_t, ndim=2] spins, int i, int j, double J):\n",
    "    \"\"\"\n",
    "    In this strategy, we use pure Python and beef up our code with JIT or Cython.\n",
    "    \"\"\"\n",
    "    cdef:\n",
    "        int N\n",
    "        double spin_l, spin_r, spin_u, spin_d\n",
    "    \n",
    "    N = spins.shape[0]\n",
    "    \n",
    "    if i == 0:\n",
    "        spin_l = spins[N-1,j]\n",
    "        spin_r = spins[i+1,j]\n",
    "    elif i == N-1:\n",
    "        spin_l = spins[i-1,j]\n",
    "        spin_r = spins[0,j]\n",
    "    else:\n",
    "        spin_l = spins[i,j-1]\n",
    "        spin_r = spins[i,j+1]\n",
    "\n",
    "    if j == 0:\n",
    "        spin_u = spins[i,N-1]\n",
    "        spin_d = spins[i,j+1]\n",
    "    elif j == N-1:\n",
    "        spin_u = spins[i,j-1]\n",
    "        spin_d = spins[i,0]\n",
    "    else:\n",
    "        spin_u = spins[i,j-1]\n",
    "        spin_d = spins[i,j+1]\n",
    "\n",
    "    return spin_l + spin_r + spin_u + spin_d\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "cdef double delta_e(np.ndarray[np.int_t, ndim=2] spins, int i, int j, double J):\n",
    "    return 2.0 * J * spins[i,j] * calc_positional_e(spins, i, j, J)\n",
    "\n",
    "\n",
    "cdef double total_mag_e(np.ndarray[np.int_t, ndim=2] spins, double J):  \n",
    "    cdef:\n",
    "        int i, j, N\n",
    "        double sum_sp\n",
    "        \n",
    "    N = spins.shape[0]\n",
    "    sum_sp = 0\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            sum_sp += (calc_positional_e(spins, i, j, J))\n",
    "            \n",
    "    return -J*sum_sp\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def metropolis_hastings2(int N, int n_steps, double beta):\n",
    "    # declare\n",
    "    cdef:\n",
    "        int s, randx, randy\n",
    "        double J, dE\n",
    "        np.ndarray[np.float_t, ndim=1] E_series = np.ones(n_steps)\n",
    "        np.ndarray[np.int_t, ndim=2] spins = np.random.choice([-1,1], size=(N,N))\n",
    "\n",
    "    srand48(123456789)\n",
    "    J = 1.0\n",
    "    E_series[0] = total_mag_e(spins, J)\n",
    "    \n",
    "    for s in range(1, n_steps):\n",
    "        randx = int(drand48() * N)\n",
    "        randy = int(drand48() * N)\n",
    "        # calculate de\n",
    "        dE = delta_e(spins, randx, randy, J)\n",
    "        # if we decrease the energy or meet boltzmann requirements, flip the spin\n",
    "        if dE < 0. or exp(-beta*dE) > drand48():\n",
    "            spins[randx, randy] *= -1\n",
    "            E_series[s] = E_series[s-1] + dE\n",
    "        else:\n",
    "            E_series[s] = E_series[s-1]\n",
    "    return spins, E_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit metropolis_hastings2(40, 500000, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1, E1 = metropolis_hastings(40, 500000, .6)\n",
    "C2, E2 = metropolis_hastings2(40, 500000, .6)\n",
    "C3, E3 = metropolis_hastings(40, 500000, .1)\n",
    "C4, E4 = metropolis_hastings2(40, 500000, .1)\n",
    "fig,ax=plt.subplots(ncols=2, figsize=(16,4))\n",
    "\n",
    "ax[0].plot(E1, label=r\"python\")\n",
    "ax[0].plot(E2, label=\"cython\")\n",
    "ax[0].legend()\n",
    "ax[1].plot(E3, label=r\"python\")\n",
    "ax[1].plot(E4, label=\"cython\")\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
