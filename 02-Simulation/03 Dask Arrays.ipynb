{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask\n",
    "\n",
    "**Dask** is a flexible parallel computing library for analytics. Dask emphasizes the following virtues:\n",
    "\n",
    "- _Familiar_: Provides parallelized NumPy array and Pandas DataFrame objects\n",
    "- _Native_: Enables distributed computing in Pure Python with access to the PyData stack\n",
    "- _Fast_: Operates with low overhead, low latency, and minimal serialization necessary for fast numerical algorithms\n",
    "- _Flexible_: Supports complex and messy workloads\n",
    "- _Scales up_: Runs resiliently on clusters up to hundreds of nodes\n",
    "- _Scales down_: Trivial to set up and run on a laptop in a single process\n",
    "- _Responsive_: Designed with interactive computing in mind it provides rapid feedback and diagnostics to aid humans\n",
    "\n",
    "## The Dask Computational Model\n",
    "\n",
    "* Parallel programming with task scheduling\n",
    "* Familiar abstractions for executing tasks in parallel on data that doesn't fit into memory\n",
    "    * Arrays, DataFrames\n",
    "* Task graphs\n",
    "    * Representation of a parallel computation\n",
    "* Scheduling\n",
    "    * Executes task graphs in parallel on a single machine using threads or processes\n",
    "    * Preliminary support for parallel execution using `dask.distributed`\n",
    "    \n",
    "## Dask Array\n",
    "\n",
    "Enabled within dask arrays are:\n",
    "\n",
    "* Arithmetic and scalar mathematics: $+, *, \\exp, \\log, \\dots$\n",
    "* Reductions along axes: `sum()`, `mean()`, `std()`\n",
    "* Tensor contractions / dot products / matrix multiply\n",
    "* Axis reordering / `transpose`\n",
    "* Slicing, `x[:100, 100:500:-1]`\n",
    "* Fancy indexing along single axes with lists or numpy arrays\n",
    "* Linear algebra `svd`, `qr`, `solve`, `lstsq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask operates on a **delayed computational model**. It builds up an expression of the computation in chunks, by creating a **Task Graph** that you can explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = da.arange(25, chunks=5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x**2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.dask.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduling Backends\n",
    "\n",
    "You can control the scheduler backend that is used by `compute`.\n",
    "\n",
    "These choices can be important in a few situations:\n",
    "* Debugging\n",
    "* Fast tasks\n",
    "* Cross-task communication\n",
    "\n",
    "*single-threaded* scheduling is the most basic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "y.compute(scheduler=\"single-threaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.compute(scheduler=\"synchronous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Scheduler\n",
    "\n",
    "* Backend that uses multiprocessing\n",
    "* Uses a process pool backend\n",
    "    * On unix-like system this is a system call to fork\n",
    "    * Calling fork creates a new child process which is a copy(-on-write) of the parent process\n",
    "    * Owns its own resources. This is \"heavy\"\n",
    "* Limitations\n",
    "    * Relies on serializing objects for the workers (slow and error prone)\n",
    "    * Workers must communicate through parent process\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.compute(scheduler=\"multiprocessing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocked Algorithms\n",
    "\n",
    "\n",
    "\n",
    "* Dask works on arrays by executing blocked algorithms on chunks of data\n",
    "* For example, consider taking the mean of a billion numbers. We might instead break up the array into 1,000 chunks, each of size 1,000,000, take the sum of each chunk, and then take the sum of the intermediate sums and divide this by the total number of observations.\n",
    "* the result (one sum on one billion numbers) is performed by many smaller results (one thousand sums on one million numbers each, followed by another sum of a thousand numbers.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = da.random.random((10000,10000), chunks=(1000,1000))\n",
    "result = x.mean()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = da.random.normal(10, 0.1, size=(20000,20000), chunks=(1000,1000))\n",
    "z = y[::100].mean(axis=0)\n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance vs. NumPy\n",
    "\n",
    "Your performance may vary. If you attempt the NumPy version then please ensure that you have more than 4GB of main memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x = np.random.normal(10., .1, size=(20000,20000))\n",
    "y = x.mean(axis=0)[::100]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x = da.random.normal(10., .1, size=(20000,20000), chunks=(1000,1000))\n",
    "y = x.mean(axis=0)[::100]\n",
    "y.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "**Conway's Game of Life** is a cellular automaton devised by British mathematician Jon Conway. \n",
    "\n",
    "The game is a zero-player game, relying on it's initial state and requiring no further input. One interacts with the Game of Life by creating an initial configuration and observing how it evolves.\n",
    "\n",
    "The universe of the *Game of Life* is an infinite, two-dimensional orthogonal grid of *square cells*, each of which is in one of two possible states: **alive** or **dead**. Every cell interacts with it's eight neighbours, which are the cells horizontally, vertically or diagonally adjacent. For each step in time, the following transitions can occur:\n",
    "\n",
    "1. Any live cell with fewer than 2 live neighbours dies, as if by underpopulation\n",
    "2. Any live cell with two or three live neighbours lives on to the next generation\n",
    "3. Any live cell with more than three live neighbours dies, as if my overpopulation\n",
    "4. Any dead cell with exactly three live neighbours becomes a live cell, as if my reproduction\n",
    "\n",
    "For edge cases, we include periodic boundary conditions:\n",
    "\n",
    "$$\n",
    "X_{-1,j}=X_{m-1,j} \\\\\n",
    "X_{m,j}=X_{0,j} \\\\\n",
    "X_{i,-1}=X_{i,n-1} \\\\\n",
    "X_{i,n}=X_{i,0} \\\\\n",
    "$$\n",
    "\n",
    "where $X$ represents the 2-D board of life.\n",
    "\n",
    "### Task 1\n",
    "\n",
    "Implement **Conway's Game of Life** using Dask. We highly recommend you make use of `da.map_overlap` to access neighbouring zones between blocks of the array. Begin with $N=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Repeat Task 1, except set $N=10^4$, with an appropriate chunksize (i.e $C=10^3$). Does it run in a reasonable amount of time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Plot 16 steps of Conway's Game of Life in 16 matplotlib plots (arranged as you like), using $N=100$. Remember that `.compute()` returns a `numpy.array`, so you will need to re-create the Dask array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Now run with $N=1000$, for 200 steps, and plot step $t$ against the mean number of alive automata at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your codes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
